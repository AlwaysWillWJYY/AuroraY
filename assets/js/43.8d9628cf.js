(window.webpackJsonp=window.webpackJsonp||[]).push([[43],{502:function(a,v,t){"use strict";t.r(v);var _=t(1),i=Object(_.a)({},(function(){var a=this,v=a._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("p",[a._v("实时输出最近一个小时内访问频率最高的10个IP，要求：")]),a._v(" "),v("ul",[v("li",[a._v("实时输出")]),a._v(" "),v("li",[a._v("从当前时间向前数的1个小时")]),a._v(" "),v("li",[a._v("QPS可能会达到10W/s")])]),a._v(" "),v("p",[a._v("这道题乍一看很像"),v("a",{attrs:{href:"https://soulmachine.gitbooks.io/system-design/content/cn/bigdata/heavy-hitters.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Top K 频繁项"),v("OutboundLink")],1),a._v("，是不是需要 Lossy Count 或 Count-Min Sketch 之类的算法呢？")]),a._v(" "),v("p",[a._v("其实杀鸡焉用牛刀，这道题用不着上述算法，请听我仔细分析。")]),a._v(" "),v("ol",[v("li",[a._v("QPS是 10万/秒，即一秒内最高有 10万个请求，那么一个小时内就有 100000*3600=360000000≈228.4228.4，向上取整，大概是 229229个请求，也不是很大。我们在内存中建立3600个"),v("code",[a._v("HashMap")]),a._v("，放在一个数组里，每秒对应一个HashMap，IP地址为key, 出现次数作为value。这样，一个小时内最多有229229个pair，每个pair占8字节，总内存大概是 229×8=232229×8=232字节，即4GB，单机完全可以存下。")]),a._v(" "),v("li",[a._v("同时还要新建一个固定大小为10的小根堆，用于存放当前出现次数最大的10个IP。堆顶是10个IP里频率最小的IP。")]),a._v(" "),v("li",[a._v("每次来一个请求，就把该秒对应的HashMap里对应的IP计数器增1，并查询该IP是否已经在堆中存在，\n"),v("ul",[v("li",[a._v("如果不存在，则把该IP在3600个HashMap的计数器加起来，与堆顶IP的出现次数进行比较，如果大于堆顶元素，则替换掉堆顶元素，如果小于，则什么也不做")]),a._v(" "),v("li",[a._v("如果已经存在，则把堆中该IP的计数器也增1，并调整堆")])])]),a._v(" "),v("li",[a._v("需要有一个后台常驻线程，每过一秒，把最旧的那个HashMap销毁，并为当前这一秒新建一个HashMap，这样维持一个一小时的窗口。")]),a._v(" "),v("li",[a._v("每次查询top 10的IP地址时，把堆里10个IP地址返回来即可。")])]),a._v(" "),v("p",[a._v("以上就是该方案的全部内容。")]),a._v(" "),v("p",[a._v('有的人问，可不可以用"IP + 时间"作为key, 把所有pair放在单个HashMap里？如果把所有数据放在一个HashMap里，有两个巨大的缺点，')]),a._v(" "),v("ul",[v("li",[a._v("第4步里，怎么淘汰掉一个小时前的pair呢？这时候后台线程只能每隔一秒，全量扫描这个HashMap里的所有pair,把过期数据删除，这是线性时间复杂度，很慢。")]),a._v(" "),v("li",[a._v('这时候HashMap里的key存放的是"IP + 时间"组合成的字符串，占用内存远远大于一个int。而前面的方案，不用存真正的时间，只需要开一个3600长度的数组来表示一个小时时间窗口。')])])])}),[],!1,null,null,null);v.default=i.exports}}]);