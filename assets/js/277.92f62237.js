(window.webpackJsonp=window.webpackJsonp||[]).push([[277],{736:function(v,_,e){"use strict";e.r(_);var o=e(1),c=Object(o.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h2",{attrs:{id:"survey-基于深度神经网络的软件漏洞检测技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#survey-基于深度神经网络的软件漏洞检测技术"}},[v._v("#")]),v._v(" Survey：基于深度神经网络的软件漏洞检测技术")]),v._v(" "),_("p",[v._v("软件漏洞检测技术可以分为3类：静态，动态，混合。静态技术包括：基于漏洞规则的，基于代码相似性的，基于符号执行的，主要依赖于对代码的分析。动态技术包括：模糊测试，污点分析，经常遇到低代码覆盖率的问题。混合的方法结合了静态和动态技术，但实际操作中效率较低。")]),v._v(" "),_("p",[v._v("数据驱动的漏洞检测方法使用模式识别、机器学习技术来学习漏洞代码表征，提高了泛化性能。现有的基于机器学习的方法主要针对源代码，因为其具有较大的可读性。深度学习技术也具有良好的应用前景，因为其可以提取非线性的高维特征，自动的提取多层次的抽象，具有更强的泛化能力。深度学习方法并不是完全不依赖代码分析，"),_("code",[v._v("AST")]),v._v("和"),_("code",[v._v("CFG")]),v._v("等元素都时常被应用 。")]),v._v(" "),_("p",[_("strong",[v._v("本文，旨在回顾基于"),_("code",[v._v("dl")]),v._v("和神经网络技术来进行漏洞检测的工作，旨在探寻哪种漏洞代码的特征表示更能体现代码的语义信息。")])]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656748190723.png",alt:"1656748190723"}})]),v._v(" "),_("p",[v._v("软件漏洞可以视作软件缺陷的一个子集，研究人员寻找漏洞代码与他们对程序的理解，安全知识，经验，直觉都相关。研究人员看到了或理解的代码语义语法信息，结合他们所知道的安全知识和经验，对目标程序的熟悉程序，使得他们有了对于漏洞代码的一些直觉和感知，这些形成了研究者心里的“代码抽象语义特征”。")]),v._v(" "),_("p",[v._v("基于"),_("code",[v._v("ml")]),v._v("的检测方法通过手动提取的特征集进行学习(传统"),_("code",[v._v("ml")]),v._v(")，或通过自动提取的代码特征进行学习("),_("code",[v._v("dl")]),v._v(")，但这类方法与人工寻找漏洞的方法之间"),_("strong",[v._v("存在一个gap，也就是说研究人员能够理解的漏洞抽象语义与"),_("code",[v._v("dl")]),v._v("方法提取出的漏洞代码语义缺乏一致性")])]),v._v(" "),_("p",[v._v("因此，这类漏洞检测方法旨在让"),_("code",[v._v("ml")]),v._v("的检测系统可以执行与人工方法一致的漏洞检测过程。从"),_("code",[v._v("ml")]),v._v("检测系统设计的角度来说，研究者可以将他们的知识和对程序的理解描述成数字特征以供"),_("code",[v._v("ml")]),v._v("系统学习，这方面还在探索中。一方面，将人们的理解转化为数字特征会造成信息丢失，另一方面，过拟合，噪声等等因素会让我们得不到最好的模型")]),v._v(" "),_("p",[v._v("基于传统"),_("code",[v._v("ml")]),v._v("的方法通过提出各种不同的特征集来"),_("code",[v._v("bridge the gap")]),v._v("，主要依赖于手工定义的特征和静态或动态代码分析工具提取到的特征，之前有研究者将这类方法分为3类："),_("strong",[v._v("基于软件度量的；基于漏洞代码模式的；基于异常的")]),v._v("。本文讨论一下这3类方法是如何"),_("code",[v._v("fill the semantic gap")]),v._v("的。")]),v._v(" "),_("ul",[_("li",[v._v("软件复杂度、修改频繁度经常被用于软件度量特征中，但没有证据表明结构复杂的代码都有漏洞，因此这种方法效果一般，若想提升需要找到更能描述漏洞代码特征的软件度量。")]),v._v(" "),_("li",[v._v("一些方法使用"),_("code",[v._v("text-mining")]),v._v("技术来提取代码模式，使用词袋，n-gram等模型，但这些模型一是无法获取代码语义，另外也无法提取长距离依赖特征，这种单纯观察单词及频率的方法效果同样不好。除了这种“flatten”的模式外，还有一些方法使用静态代码分析工具提取出代码的一些结构化的模式，比如"),_("code",[v._v("AST")]),v._v("可以反映代码结构，"),_("code",[v._v("CFG")]),v._v(","),_("code",[v._v("DFG")]),v._v(","),_("code",[v._v("PDG")]),v._v("可以反应程序的流程与变量之间的依赖关系。这种方法提取的特征集就基于高维的源代码结构，可以很大程度上贴近研究人员寻找漏洞的过程。")]),v._v(" "),_("li",[v._v("有些研究认为漏洞代码模式是属于和正常代码模式不同的异常模式，这些研究者旨在强调寻找漏洞的原因而不是寻找漏洞。然而，这种方法只能检测特定类型的漏洞，比如从import和函数调用提取的特征只能训练检测头文件、库相关的漏洞，且具有高的假阳性率。")])]),v._v(" "),_("p",[v._v("基于"),_("code",[v._v("dl")]),v._v("的方法可以学习到高纬度更加复杂和抽象的代码表征，能够自动的学习更加"),_("code",[v._v("general")]),v._v("的特征，将研究者从主观的、耗费人力的、易错的任务中解放出来，而且可以灵活的使用各种网络结构去获取不同应用场景的特征。以上特点使得研究者可以通过"),_("code",[v._v("dl")]),v._v("来获取代码语义。理解代码上下文依赖，自动的提取泛化性强的高维特征，以此能更好的理解代码语义并"),_("code",[v._v("reduce the semantic gap")]),v._v("。")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("获取代码表征的网络结构")])])]),v._v(" "),_("p",[_("code",[v._v("FCN")]),v._v("网络：全连接网络，也叫"),_("code",[v._v("MLP")]),v._v("，是最先被用于漏洞检测的神经网络模型，相比于传统"),_("code",[v._v("ml")]),v._v("方法中的"),_("code",[v._v("RF")]),v._v("、"),_("code",[v._v("SVM")]),v._v("等等，"),_("code",[v._v("FCN")]),v._v("可以提取到更高维的表征。另外，"),_("code",[v._v("FCN")]),v._v("还有一项优点是可以处理任意大小的输入，也就是可以处理多种类型的特征。")]),v._v(" "),_("p",[_("code",[v._v("CNN")]),v._v("网络：其可以学习到空间结构化的数据，在"),_("code",[v._v("nlp")]),v._v("任务中，可以通过构造"),_("code",[v._v("context window")]),v._v("，来获取单词的上下文信息，因此"),_("code",[v._v("CNN")]),v._v("网络也常被用于漏洞检测中。")]),v._v(" "),_("p",[_("code",[v._v("RNN")]),v._v("网络："),_("code",[v._v("RNN")]),v._v("处理序列特征非常方便，其在漏洞检测任务中应用的次数最多，包括各种"),_("code",[v._v("RNN")]),v._v("的变体，"),_("code",[v._v("双向RNN")]),v._v("，"),_("code",[v._v("GRU")]),v._v("，"),_("code",[v._v("LSTM")]),v._v("，等等。")]),v._v(" "),_("p",[v._v("其他网络："),_("code",[v._v("DBN深度置信网络")]),v._v("，"),_("code",[v._v("VAEs变分自编码器")]),v._v("等等。")]),v._v(" "),_("p",[_("strong",[v._v("基于深度学习的源代码漏洞检测领域的过去工作主要可以分为4类，相当于对4种不同类型的代码表征进行学习：基于图的表征、基于序列的表征、基于text的表征、混合表征。")])]),v._v(" "),_("blockquote",[_("p",[v._v("Graph-Based Feature Representations")])]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656748985766.png",alt:"1656748985766"}})]),v._v(" "),_("ul",[_("li",[_("h6",{attrs:{id:"以-以上介绍了基于图的表征的几项研究成果-这里的图包括ast-cfg-pdg-ddg等等-以此作为dnn的输入来学习代码表征。对于第二篇文章-作者从源代码中提取出ast-并保存了3类节点-函数调用和类实例创建节点、声明节点、控制流节点-将节点转换为token序列-注意在cross-project任务时将project-specific的token替换为general-name-并encoding成向量使用dbn来进行学习和训练"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#以-以上介绍了基于图的表征的几项研究成果-这里的图包括ast-cfg-pdg-ddg等等-以此作为dnn的输入来学习代码表征。对于第二篇文章-作者从源代码中提取出ast-并保存了3类节点-函数调用和类实例创建节点、声明节点、控制流节点-将节点转换为token序列-注意在cross-project任务时将project-specific的token替换为general-name-并encoding成向量使用dbn来进行学习和训练"}},[v._v("#")]),v._v(" 以 以上介绍了基于图的表征的几项研究成果，这里的图包括"),_("code",[v._v("AST")]),v._v(","),_("code",[v._v("CFG")]),v._v(","),_("code",[v._v("PDG")]),v._v(","),_("code",[v._v("DDG")]),v._v("等等，以此作为"),_("code",[v._v("DNN")]),v._v("的输入来学习代码表征。对于第二篇文章，作者从源代码中提取出"),_("code",[v._v("AST")]),v._v("，并保存了3类节点（函数调用和类实例创建节点、声明节点、控制流节点），将节点转换为token序列(注意在cross-project任务时将project-specific的token替换为general name)，并encoding成向量使用"),_("code",[v._v("DBN")]),v._v("来进行学习和训练")])]),v._v(" "),_("li",[_("p",[v._v("第三篇文章，同样是基于"),_("code",[v._v("AST")]),v._v("的方法，将"),_("code",[v._v("AST")]),v._v("使用深度优先遍历"),_("code",[v._v("DFT")]),v._v("的方式转换为序列，再采用"),_("code",[v._v("Bi-LSTM")]),v._v("进行特征学习，标签不是手动完成的，而是采用软件复杂度指标，因为复杂的软件含有漏洞的可能性较高。本文所得到的结果是漏洞的样本的比例，比如200个样本中47%是确实有漏洞的，可以借鉴的是若漏洞函数没有标签，则可以用复杂度指标代替。")])]),v._v(" "),_("li",[_("p",[v._v("第四篇文章和第三篇文章的处理方法相似，但其对于token的编码方式不是直接映射的方式，而是通过"),_("code",[v._v("word2vec（CBOW）")]),v._v("方式embedding成向量，且在"),_("code",[v._v("Bi-LSTM")]),v._v("层后面家里一个max-pooling层和2层全连接层，来进行特征提取。该文采用迁移学习的方式，首先在一部分数据集上训练神经网络模型，之后再目标数据集上使用训练过的模型继续训练，得到"),_("code",[v._v("AST")]),v._v("的表征，连入"),_("code",[v._v("RF")]),v._v("分类器进行分类检测。")])]),v._v(" "),_("li",[_("p",[v._v("第五篇文章使用"),_("code",[v._v("seq2seq")]),v._v("的"),_("code",[v._v("LSTM")]),v._v("模型来进行漏洞检测，作者声称可以自动的学习代码的语法和语义信息。作者提取"),_("code",[v._v("AST")]),v._v("并将其转化为token序列，建立一个查找表来将token映射为固定长度的向量，然后将embedding后的token序列输入到"),_("code",[v._v("seq2seq LSTM")]),v._v("网络中，之后使用mean pooling将所有token的状态聚合起来保存在一个向量中，作为该函数的表征用于within-project的漏洞检测。对于cross-project情况，对训练集中的token进行k-means聚类，则对于一个新文件，计算文件中所有token向量与每个聚类中心的距离，生成该文件的特征向量，用于cross-project的检测。")])])]),v._v(" "),_("p",[v._v("总之，基于图的表征的漏洞检测方法多是采用"),_("code",[v._v("AST")]),v._v("提取代码表征，因为相比于"),_("code",[v._v("CFG")]),v._v("等图，"),_("code",[v._v("AST")]),v._v("蕴含着更多的代码层次结构的语法和语义特征，但是并没有研究表明"),_("code",[v._v("AST")]),v._v("比"),_("code",[v._v("CFG")]),v._v("、"),_("code",[v._v("PDG")]),v._v("、"),_("code",[v._v("DDG")]),v._v("提供的语义信息更多，也没有研究可以评估哪种神经网络模型可以获取对于漏洞检测更有效的代码语义信息。而且，目前的研究大部分是将图表征flatten后处理，如果使用图神经网络和一些图"),_("code",[v._v("embdding")]),v._v("技术处理图表征，可能会对于漏洞检测有更大的帮助。")]),v._v(" "),_("blockquote",[_("p",[v._v("Sequence-Based Feature Representations")])]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656749661335.png",alt:"1656749661335"}}),v._v("本部分回顾了使用"),_("code",[v._v("DNN")]),v._v("学习基于序列的顺序特征的检测方法，包括基于系统执行跟踪、函数调用序列，语句执行流序列等等。")]),v._v(" "),_("ul",[_("li",[_("p",[v._v("第一篇文章在二进制层面预测OS的内存破坏漏洞，通过反汇编得到一系列标准C函数的调用序列作为静态特征， 获得动态特征需要在有限的时间段内执行程序。在执行过程中，作者监视程序的事件并收集调用序列。然而，获得的动态调用序列包含大量函数调用的参数，这些参数是低级计算值。作者需要将它们分类为子类型，以减少论点类型的多样性 。该文采用"),_("code",[v._v("n-gram")]),v._v("模型和"),_("code",[v._v("word2vec")]),v._v("模型来将调用序列信息转化为向量表征，之后通过"),_("code",[v._v("LR")]),v._v(","),_("code",[v._v("FCN")]),v._v(","),_("code",[v._v("RF")]),v._v("等方法进行漏洞检测分类。")])]),v._v(" "),_("li",[_("p",[v._v("第二篇文章比较了各种类型的"),_("code",[v._v("DNN")]),v._v("在处理动态函数调用序列表征上面的效果，"),_("code",[v._v("CNN")]),v._v(", "),_("code",[v._v("LSTM")]),v._v(","),_("code",[v._v("CNN-LSTM")]),v._v(","),_("code",[v._v("FCN")]),v._v("共4种类型。也是通过执行有限时间的程序来获得调用序列。得到序列后使用subtype来代替type以减少参数类型的多样性，最后使用"),_("code",[v._v("keras")]),v._v("将每个"),_("code",[v._v("token")]),v._v("转化为一个整数，加上补充和截断序列就转化为固定长度整数序列，使用"),_("code",[v._v("DNN")]),v._v("训练即可。")])]),v._v(" "),_("li",[_("p",[v._v("这里的第三篇和第四篇文章都是基于代码小工具, 在"),_("code",[v._v("VulDeepecker")]),v._v("中该结构针对两种类型的漏洞准确的捕捉了代码中的语义特征，实现了95%的"),_("code",[v._v("F1-score")]),v._v("，堪称里程碑式的成果，包括"),_("code",[v._v("SyseVR")]),v._v("也是其延续的成果，但由于code gadget只能由商业软件生成，因此这类工作的复现难度较大。")])])]),v._v(" "),_("p",[v._v("总之，相比基于图的表征，基于序列的表征本身就是“flattened”的，更容易被神经网络处理，但由于检测粒度不同，现在无法说明是"),_("code",[v._v("ASTs")]),v._v("效果好还是代码小工具效果好，未来需要有一个benchmark数据集以供这些方法相互比较。")]),v._v(" "),_("blockquote",[_("p",[v._v("Text-Based Feature Representations")])]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656744245279.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("本部分回顾了一些使用"),_("code",[v._v("DNN")]),v._v("学习代码文本特征的文章，代码文本指的是源代码、汇编指令、词法分析后的源代码文本等")])]),v._v(" "),_("ul",[_("li",[_("p",[v._v("第一篇文章将Java源代码文件转化为token序列，随后使用N-gram模型将token序列转化为向量，该文假定漏洞模式可以通过分析源代码token的频率来获得。该文使用了一个深度"),_("code",[v._v("FCN")]),v._v("网络，达到了93%的检测准确率。")])]),v._v(" "),_("li",[_("p",[v._v("第二篇文章在汇编代码的级别检测C程序的漏洞，旨在从汇编指令级别提取漏洞的模式。该文基于"),_("code",[v._v("word2vec")]),v._v("模型提出了"),_("code",[v._v("instruction2vec")]),v._v("方法，为汇编代码和对应的固定长度的向量提供了一个对照的查找表。由于一个汇编指令有一个操作码和两个操作数，因此每个指令可以编码为9*m维的向量，由于一个函数包含多条指令，因此函数级别的汇编代码就可以编码为向量输入到CNN进行特征学习和提取")])]),v._v(" "),_("li",[_("p",[v._v("第三篇文章使用CNN进行函数级别的漏洞检测，作者实现了一个C/C++的词法分析器将源代码转化为token序列。为了提取关键词的信息，词法分析器在词法分析过程中将单词数量Minimize到156个，也就是除了C/C++的关键词、操作符等，不影响编译的部分被去掉了，之后对token序列进行embedding。该文使用"),_("code",[v._v("CNN+maxpooling")]),v._v("+"),_("code",[v._v("2层GRU+maxpooling")]),v._v("来进行特征提取，将提取到的特征应用于随机森林中进行分类，得到检测结果。")])]),v._v(" "),_("li",[_("p",[v._v("第四篇文章提出了一个最大发散序列自编码器，在"),_("code",[v._v("VAE")]),v._v("的基础上建立，用于学习机器指令序列的表征，实现在二进制级别检测代码漏洞。作者为漏洞和非漏洞两个类别设定了可学习的高斯先验，maximize这两个类别的"),_("code",[v._v("WS")]),v._v("距离或"),_("code",[v._v("KL")]),v._v("散度。该编码器可以接一些独立的分类器("),_("code",[v._v("SVM")]),v._v(", "),_("code",[v._v("RF")]),v._v(")来进行漏洞检测。该文的数据集是来自windows和Linux的二进制数据集，Capstone是一个将二进制转化为具有更多语义信息的汇编代码的一个框架，本文将汇编指令分为操作码和指令信息（例如，内存位置、寄存器）两部分，各有一个词汇表，分别进行embedding，最后"),_("code",[v._v("concat")]),v._v("到一起就得到了整个汇编指令的编码。")])]),v._v(" "),_("li",[_("p",[v._v("之前的文章展示了"),_("code",[v._v("DBN")]),v._v("和"),_("code",[v._v("FCN")]),v._v("可以提取向量的高维表征，同时可证明了"),_("code",[v._v("CNN")]),v._v("和各种"),_("code",[v._v("RNN")]),v._v("变体可以提取源代码、"),_("code",[v._v("AST")]),v._v("的上下文模式和结构。然而没有研究表明传统的"),_("code",[v._v("DNN")]),v._v("可以理解代码上下文值的变化，直到第五篇文章的出现填补了这一空缺 ，第五篇文章使用记忆网络跟踪不同变量的值随着语句的变化，研究证明，记忆网络可以通过对多条赋值语句的跟踪来判断是否会发生缓冲区溢出漏洞。监视多个变量值的变化不仅要求网络要理解代码的结构，同时要求网络具有记忆变量和其对应值并可以进行改变的能力，因此需要对传统的网络结构增加额外的记忆模块来学习超长范围的特征关系。")])]),v._v(" "),_("li",[_("p",[v._v("该文中记忆网络的实现，用于对缓冲区溢出漏洞实现端到端的检测，输入是源代码，输出是程序中是否含有漏洞，检测粒度是语句。将每一token编码为V维的one-hot向量，假设一个程序一共N行，每行编码为两个矩阵，一个是内容矩阵存储该行的语义，另一个是地址矩阵存储该行代码在程序中的位置信息")])]),v._v(" "),_("li",[_("p",[v._v("检查一行代码是否包含缓冲区溢出漏洞，将这一行作为query，使用地址相关的编码进行encoding。使用attention机制，得到每一行与query的attention值，将attention值与记忆值相乘得到响应向量，响应向量越大证明该行具有和query相关的信息。将响应向量应用到权重矩阵中生成输出0或1，代表是否具有向量。作者使用10000个实例程序在4个缓冲区漏洞等级上进行测试，发现记忆网络的效果显著好于"),_("code",[v._v("CNN")]),v._v("和"),_("code",[v._v("LSTM")]),v._v("网络。")])]),v._v(" "),_("li",[_("p",[v._v("上述使用的合成代码在语法上无效，因此无法编译代码，并且合成代码没有任何控制流，这不能反映真实场景。因此，第六篇文章对这些缺点进行了以下改进： 首先其提出了一个更真实的数据集"),_("code",[v._v("s-bAbI")]),v._v("包含着语法准确并有正常控制流的C程序。其次，作者引入了行号这一概念，使得记忆网络在处理代码的时候可以考虑代码的顺序。该文还引入了"),_("code",[v._v("dropout")]),v._v("防止过拟合，在"),_("code",[v._v("s-bAbI")]),v._v("数据集上取得了91.7%的准确率，显著超过了开源的漏洞检测工具。")]),v._v(" "),_("p",[v._v("应用"),_("code",[v._v("DNNs")]),v._v("对代码text进行特征学习，以此来实现漏洞检测。与其他类别方法不同的是，本类别的方法不适应任何的代码分析工具，直接使用代码文本本身作为输入去学习代码表征，随着网络结构的复杂性提高，代码处理所需要做的不断减少，这可能是未来的一个趋势。")])])]),v._v(" "),_("blockquote",[_("p",[v._v("Mixed Feature Representations")])]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656744376476.png",alt:"1656744376476"}})]),v._v(" "),_("p",[v._v("**本部分回顾了一些基于多种混合特征的漏洞检测文章 **")]),v._v(" "),_("ul",[_("li",[_("p",[v._v("第一篇文章提出了一个检查安卓二进制可执行文件中的漏洞。作者对"),_("code",[v._v("APK")]),v._v("文件进行反编译，得到"),_("code",[v._v("smali")]),v._v("文件和"),_("code",[v._v("dalvik")]),v._v("指令，从"),_("code",[v._v("smali")]),v._v("文件中得到两种类型的特征：由"),_("code",[v._v("dalvik")]),v._v("指令的频率所显示的token特征，以及由"),_("code",[v._v("smali")]),v._v("文件的"),_("code",[v._v("AST")]),v._v("生成的语义特征。"),_("code",[v._v("AST")]),v._v("中语义特征的获取作者采用了"),_("code",[v._v("DFS")]),v._v("遍历"),_("code",[v._v("AST")]),v._v("生成"),_("code",[v._v("AST")]),v._v("序列，将序列通过编码token频率特征的方式来embedding，最后将两种类型的特征混合后输入"),_("code",[v._v("FCN")]),v._v("进行训练检测。")])]),v._v(" "),_("li",[_("p",[v._v("第二篇文章基于漏洞检测中的两类特征。第一类特征是直接从源代码中提取的源代码特征，第二类是从Clang或"),_("code",[v._v("LLVM")]),v._v("中构建的"),_("code",[v._v("CFG")]),v._v("特征。对于源代码特征，作者实现了一个C/C++的词法分析器去将源代码函数转化为token序列，变量名被map为相同的标识符，但在一个函数中独立的变量名要有单独的索引， 以跟踪变量的重新出现 ,接着使用"),_("code",[v._v("word2vec")]),v._v("进行embedding。对于构建特征，作者编译了程序，并从函数级别的"),_("code",[v._v("CFG")]),v._v("图和指令级别的基本块进行特征提取，生成变量的def-use矩阵( 特征集包括每个基本块中发生的操作以及变量的定义和使用 )，并编码为固定长度的向量。最终，将以上两类特征输入到CNN，或RF等传统分类器中，验证了模型结果。")])]),v._v(" "),_("li",[_("p",[v._v("第三篇文章使用2个"),_("code",[v._v("bi-LSTM")]),v._v("网络来获取两种不同类型的特征表示。一个是针对"),_("code",[v._v("SARD")]),v._v("中合成的漏洞测试用例的"),_("code",[v._v("AST")]),v._v("特征，另一个针对真实世界的样本的源代码特征。训练结束后，针对测试样本，提取这两种类型的特征，聚合起来使用传统的ML模型进行分类检测， 实验表明利用两个脆弱性相关数据源的框架比仅使用一个数据源更有效 。")]),v._v(" "),_("p",[v._v("总结该部分的3篇文章，均是使用了多种类型的特征一并输入进行训练和检测漏洞，并证明了其效果优于使用单一特征的检测方法。利用神经网络学习更多不同类型的特征来获取与漏洞相关的代码语义进行检测可能是未来的方向。")]),v._v(" "),_("blockquote",[_("p",[v._v("C H A L L E N G E S     A N D     F U T U R E      D I R E C T I O N S")])])])]),v._v(" "),_("p",[_("strong",[v._v("尽管已有研究提出了各种类型的特征集，并应用不同的网络结构来缩小语义差距，但仍有很长的路要走。接下来将讨论挑战和未来工作，并分享一些见解")])]),v._v(" "),_("ul",[_("li",[_("p",[v._v("大的ground-truth数据集")]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656745853362.png",alt:"1656745853362"}})]),v._v(" "),_("p",[v._v("数据集是阻碍该领域研究的最大障碍，目前该领域的研究方法普遍采用自己构建的数据集，因为不同的方法对应不同的检测粒度，对应的标签也就不同。因此，迫切需要一个标准的基准数据集，作为评估和比较所提出方法有效性的统一度量标准。[58]是第一个提出这种基准数据集的工作，提出了一个包含"),_("code",[v._v("9")]),v._v("个数据集的开源"),_("code",[v._v("C")]),v._v("代码，包含函数和文件两个检测粒度。理想情况下，标准的基准测试数据集应该针对多个检测粒度级别的方法进行精心定制，并且应该包含大量的合成和真实代码示例，以便进行定性和定量的评估和比较。上图列出了现有的开源代码真实世界漏洞数据集，然而这些数据集很多数量不足，标记量不足，存在各种各样的问题。")])]),v._v(" "),_("li",[_("p",[v._v("代码分析和神经学习")])])]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656746258703.png",alt:"1656746258703"}}),v._v("从以上文章可以看出应用于漏洞检测中的神经网络模型正变得越来越复杂，也能更有效的提取漏洞代码的语义信息，从"),_("code",[v._v("MLP")]),v._v("到"),_("code",[v._v("CNN")]),v._v("、"),_("code",[v._v("LSTM")]),v._v("，再到"),_("code",[v._v("记忆网络")]),v._v("等等。还有一个趋势是随着网络的逐渐复杂，需要在代码分析上花费的功夫在不断降低。在使用"),_("code",[v._v("MLP")]),v._v("作为网络时，需要使用从"),_("code",[v._v("CFG")]),v._v("和"),_("code",[v._v("DDG")]),v._v("中获得的手工特征，提取"),_("code",[v._v("CFG")]),v._v("和"),_("code",[v._v("DDG")]),v._v("需要大量的代码分析专业知识。在使用CNN时，将源代码进行词法分析即可应用，最近的记忆网络则是直接使用源代码作为输入，不需要进行代码分析。上图展示了一些代码分析方法的trade-off，权衡模型难度和代码处理的难度才能得到最好的方法。")]),v._v(" "),_("ul",[_("li",[v._v("具有语义保留的神经模型")])]),v._v(" "),_("p",[v._v("最近研究提出的将生成对抗网络（"),_("code",[v._v("GAN")]),v._v("）[37]应用于修复C/C++合成代码示例上的漏洞，证明了神经模型在理解代码逻辑和语义方面的能力。在自然语言处理领域，序列建模和自然语言理解的最新进展令人鼓舞。例如，"),_("code",[v._v("Transformer")]),v._v("神经网络架构[107]基于自注意力机制，在自然语言翻译任务中优于最先进的方法，并在自然语言理解方面表现出强大的能力。  自然语言处理领域富有成果的研究成果已越来越多地被应用于软件工程研究[28]，例如，采用"),_("code",[v._v("Word2vec")]),v._v("和"),_("code",[v._v("Bi LSTM")]),v._v("进行代码语义学习[56]、[61]。应用"),_("code",[v._v("Transformer")]),v._v("之类的模型来更好地理解代码分析任务（如漏洞发现）的编程语言语义。  将基于树/图的神经网络应用于漏洞检测。许多程序表示形式是树或图。例如，"),_("code",[v._v("AST")]),v._v("在树的层次结构中描述代码组件。"),_("code",[v._v("CFG")]),v._v("可以是显示程序控制流的有向图，"),_("code",[v._v("PDG")]),v._v("使用图表示法显式表示数据依赖和控制依赖。现有研究利用这些程序表示，但以其“扁平”形式，并使用"),_("code",[v._v("FCN")]),v._v("、"),_("code",[v._v("CNN")]),v._v("或"),_("code",[v._v("RNN")]),v._v("以“顺序”方式处理它们，这可能不可避免地丢失包含可能存在漏洞的代码语义的层次和/或结构信息。因此，为了更好地处理和保存隐藏在基于树/图的程序表示中的层次和/或结构信息 , 基于树/图的神经网络是理想的选择  [105]中提出的树结构"),_("code",[v._v("LSTM（TS-LSTM）")]),v._v("网络和[97]中的递归神经网络证明了它们在处理以树结构组织的自然语言的句法特性方面的有效性 并且还有大量基于图形的神经网络（也称为图形神经网络（"),_("code",[v._v("GNN")]),v._v("）[118]），可以直接对基于图形的程序表示（例如"),_("code",[v._v("CGF")]),v._v("和"),_("code",[v._v("PDG")]),v._v("）进行操作，以学习指示潜在易受攻击代码的高级特征表示。例如，图卷积网络（"),_("code",[v._v("GCN")]),v._v("）[48]和图自动编码器（"),_("code",[v._v("GAE")]),v._v("）[14]可以帮助学习图结构中呈现的程序表示，以及描述代码实体关系的节点和边之间的相互依存关系 。")]),v._v(" "),_("ul",[_("li",[v._v("代码表征学习")])]),v._v(" "),_("p",[v._v("从数据处理的角度来看，可以通过设计更好的特征工程技术来整合丰富的代码语义和语法特征，以提高模型学习能力。高质量的特征一方面有益于模型学习，另一方面也使得模型的复杂度得到降低。由于漏洞模式和语句的多样性，定义普遍表征所有类型漏洞的特征集几乎是不可行和不可能的 , 定义反映特定类型漏洞特征的特征集可以是一种折衷的选择 。")]),v._v(" "),_("p",[v._v("另外，要想下游模型能够学习到丰富的代码语法语义信息，单词的"),_("code",[v._v("embedding")]),v._v("需要更好，目前的"),_("code",[v._v("embedding")]),v._v("主要是基于频率的("),_("code",[v._v("n-gram")]),v._v(")或者基于概率的("),_("code",[v._v("word2vec")]),v._v(")，"),_("code",[v._v("n-gram")]),v._v("编码包含的语义信息极少，"),_("code",[v._v("word2vec")]),v._v("也只能得到小范围内的上下文依赖，未来需要更好的"),_("code",[v._v("embedding")]),v._v("模型，争取编码更多的语义信息。")]),v._v(" "),_("ul",[_("li",[v._v("模型可解释性")])]),v._v(" "),_("p",[v._v("经网络模型就像黑盒子，模型的预测和分类过程研究者是不可见的。其不像线性模型，层次结构给其可解释性带来了难度。为了解决这个问题，"),_("code",[v._v("LIME")]),v._v("提出通过在预测样本周围局部学习一个简单且可解释的模型(如线性或决策树模型)，可以为任何模型提供可解释性。然而，当使用神经网络模型作为特征提取器，再将提取的特征用于训练分类器时，"),_("code",[v._v("LIME")]),v._v("并不适用。")]),v._v(" "),_("p",[v._v("注意力机制可以为神经网络模型提供一定程度的可解释性，通过注意力机制可以是"),_("code",[v._v("CNN")]),v._v("或"),_("code",[v._v("RNN")]),v._v("模型聚焦于输入序列的某一部分。最近，注意力网络已被应用于缺陷预测，为基于"),_("code",[v._v("DL")]),v._v("的可解释的代码分析和漏洞/缺陷预测提供了一个有前景的研究方向。")]),v._v(" "),_("blockquote",[_("p",[v._v("结论")])]),v._v(" "),_("p",[v._v("神经网络在漏洞检测中的应用是一个不成熟的研究领域，有许多问题尚未解决。随着ML领域的快速发展，ML和深度学习方面的重大进展将为漏洞检测工具包增加价值。 现有的方法应用神经网络提取特征进行漏洞检测，试图弥补从业者对漏洞的理解和神经网络可以学习到的语义信息之间的gap差距。神经网络模型的表征能力和可定制结构的潜力吸引力越来越多的研究者投身代码漏洞检测领域中来。")]),v._v(" "),_("h2",{attrs:{id:"基于神经网络图嵌入的跨平台二进制代码相似性检测"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于神经网络图嵌入的跨平台二进制代码相似性检测"}},[v._v("#")]),v._v(" "),_("strong",[v._v("基于神经网络图嵌入的跨平台二进制代码相似性检测")])]),v._v(" "),_("ul",[_("li",[_("p",[_("code",[v._v("图嵌入")]),v._v(" 先解释一个最重要的术语“图嵌入”，图嵌入的目的是降维，在保留图特征的前提下将图经过非线性变换成一维向量。 相较于以前通过比对两个二进制函数的"),_("code",[v._v("CFG")]),v._v("图(函数的控制流程图)的相似性去判断代码相似性(图比对)，现在提取"),_("code",[v._v("CFG")]),v._v("图嵌入后对向量做相似性比较，其时间代价是不是更小，而且特征更为抽象。 但是，利用"),_("code",[v._v("CFG")]),v._v("图嵌入做二进制代码的相似性检测，前人已经做过了(Genius)，而且Genius在对"),_("code",[v._v("CFG")]),v._v("做嵌入之前，将"),_("code",[v._v("CFG")]),v._v("转换为"),_("code",[v._v("ACFG")]),v._v("，即提取控制流程图中平台无关的基本块属性和块间属性。 Genius使用二部图匹配算法和密码本作为基础去计算"),_("code",[v._v("ACFG")]),v._v("的嵌入，具体做法是使用聚类算法训练出一个具有代表性的"),_("code",[v._v("ACFG")]),v._v("的特征向量集合，形成一个"),_("code",[v._v("ACFG")]),v._v("与特征向量对应的密码本，对于新的待计算"),_("code",[v._v("ACFG")]),v._v("，通过二部图匹配算法与码本中每个代表性的"),_("code",[v._v("ACFG")]),v._v("进行相似性比对，新"),_("code",[v._v("ACFG")]),v._v("的嵌入即为与其最相似的代表性"),_("code",[v._v("ACFG")]),v._v("的特征向量。 Genius的图嵌入生成方法时间代价较高，而且码本质量取决于训练数据规模。 Gemini(论文实现的原型)采用"),_("code",[v._v("Structure2vec")]),v._v("算法计算"),_("code",[v._v("ACFG")]),v._v("的图嵌入，该算法从空间结构的相似性去定义相似度，通过评价函数整合节点和它n层邻居的信息，将这些信息压缩成一个有限维的非线性向量。"),_("strong",[v._v("原产的"),_("code",[v._v("Structure2vec")]),v._v("算法并不能直接用于计算"),_("code",[v._v("ACFG")]),v._v("图嵌入")]),v._v("  ，Gemini使用了其变种，首先对"),_("code",[v._v("ACFG")]),v._v("每个节点使用变种的"),_("code",[v._v("Structure2vec")]),v._v("算法压缩基本块属性和图结构信息到一个特征向量中，然后使用聚合函数将所有节点的特征向量聚合成一个向量。"),_("strong",[v._v("它可以整合"),_("code",[v._v("CFG")]),v._v("中基本块信息和基本块间的结构信息，并把它们映射成一个非线性向量的表示形式")]),v._v("。Gemini做二进制代码的相似性分析基础架构都有了(即基于"),_("code",[v._v("Structure2vec")]),v._v("算法生成2个二进制函数的"),_("code",[v._v("ACFG")]),v._v("图嵌入，然后通过比较2个嵌入向量的相似性)，神经网络有什么用？这时，神经网络算法就该出场了，给它安排的活是 训练"),_("code",[v._v("Structure2vec")]),v._v("算法的参数，这时候有公式可能更直观些。")]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656579095605.png",alt:"1656579095605"}})]),v._v(" "),_("p",[v._v("如公式所示，这是Gemini选定用来在"),_("code",[v._v("Structure2vec")]),v._v("模型中做非线性映射的模型，这个非线性映射的输入xv是节点的基本块属性信息，u∈N(v)是节点的邻接节点信息，经过映射可得到一个节点的特征向量，而整个"),_("code",[v._v("ACFG")]),v._v("特征向量是通过所有节点聚合得来。 其中，σ(·)是一个非线性变化， Gemini为了使非线性变化较为强大，就把σ(·)设计成n层全连接神经网络；"),_("code",[v._v("W1")]),v._v("是一个d*p矩阵，d是xv(基本块属性)的长度，p是生成的嵌入长度，"),_("code",[v._v("W1")]),v._v("也是待训练参数。 目前，总结来说就是，基础是"),_("code",[v._v("Structure2vec")]),v._v("模型中加入神经网络来训练其非线性变化的模型，再用聚合函数将"),_("code",[v._v("ACFG")]),v._v("节点的特征向量聚合成"),_("code",[v._v("ACFG")]),v._v("的图嵌入，结合神经网络的图嵌入最终输出的依然是"),_("code",[v._v("ACFG")]),v._v("图嵌入(也可以称为"),_("code",[v._v("ACFG")]),v._v("的特征向量)。 Siamese网络 在前面已经介绍过本文采用的二进制代码相似比对的方式就是比较图嵌入，那么图嵌入计算出来后，如何处理可以得到相似度的结果，答案就是Siamese网络，其模型特点是在样本量少的情况下识别类型。")]),v._v(" "),_("p",[_("img",{attrs:{src:"C:%5CUsers%5CAuroraY%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1656578013923.png",alt:"1656578013923"}})])]),v._v(" "),_("li",[_("p",[v._v("Siamese模型本身包括了目标降维模块，正好上文的融入神经网络的图嵌入即可作为模型中的降维模块。整体模型的输入是两个待比较二进制函数的"),_("code",[v._v("ACFG")]),v._v("，经过嵌入网络得到降维的特征向量"),_("code",[v._v("u1")]),v._v("和"),_("code",[v._v("u2")]),v._v("，然后计算二者余弦距离，通过阈值判定结果是-1(非相似)，还是1(相似)。当然，训练过程都有真实的标签，以便整个模型不断调整参数。 跨平台 跨平台指的是什么呢？即，二进制代码相似性比较与二进制代码所处平台、使用的编译器和优化选项无关，训练出的"),_("code",[v._v("ACFG")]),v._v("图嵌入计算模型和使用的相似比对方法与以上条件无关。 又是如何做的呢？总结起来有两点工作： 继承了Genius提取二进制函数"),_("code",[v._v("CFG")]),v._v("中与平台无关性的属性，6个基本块属性： "),_("code",[v._v("字符串常量、数字常量，传递指令数量，调用指令数量，运算指令数量，指令总数量")]),v._v("； 1个基本块间属性： "),_("code",[v._v("基本块子代数量")]),v._v("。 需要注意的是，Gemini抛弃了Genius中使用的另一个基本块间属性“介数中心性”(betweenness)，原因是该属性提取较慢，与模型的最终效果影响也不大。 训练数据采集的平台无关性，Gemini使用同一份源码在不同系统平台、不同编译器、不同编译器优化选项的条件下生成大量带标签的样本。 另外有一个样本处理的细节是不会将同一份源码编译后的二进制代码分开在训练集、验证集和测试集。 个人认为这样做有助于在训练模型的过程中充分考虑到编译的不同条件，以训练出平台无关性模型。 在测试时，也可以用其它源码生成的样本来验证未经训练的数据是否符合模型。 总结标题 在介绍了论文中的图嵌入、神经网络、跨平台的概念及论文中的应用，那论文整体的思路也都明确了。总结下标题，目标是做跨平台二进制代码的相似性检查，方法是加入神经网络的图嵌入.")])])]),v._v(" "),_("p",[_("strong",[v._v("论文总结")])]),v._v(" "),_("ul",[_("li",[v._v("对于二进制代码，它的变化并不是无穷无尽的，因为它的产生是来源于机器规则，它看起来复杂难懂，但其内部必然藏着巨大的规律性 ，而深度学习的优势就在于挖掘这种潜在的规律，我目前认为“深度学习是只要你有，我就一定能挖出来”。至于怎么挖，用什么样的算法和模型，这需要人去建立二进制数据和模型的联系和关系，这篇论文是一个很好的结合，我相信未来，在这个方向上的继往开来者会很多。 对于"),_("code",[v._v("ACFG")]),v._v("中的属性，不同平台、编译器、优化选项生成的二进制代码，有些属性值(运算指令、call指令、指令总数，甚至常量值等)存在噪声，它的成分并不是全部用来体现函数本身，有些仅是某个平台和编译器或优化选项特有的，例如一些安全机制，栈随机值保护、栈指针验证、异常处理等，在不同平台和优化选项中，这些可能出现，也可能不出现。训练模型时需要考虑这些，在模型真正用于实际时也需要考虑这些。")])])])}),[],!1,null,null,null);_.default=c.exports}}]);