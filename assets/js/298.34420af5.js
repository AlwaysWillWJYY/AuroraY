(window.webpackJsonp=window.webpackJsonp||[]).push([[298],{756:function(v,_,C){"use strict";C.r(_);var P=C(1),U=Object(P.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h2",{attrs:{id:"操作系统"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#操作系统"}},[v._v("#")]),v._v(" 操作系统")]),v._v(" "),_("p",[v._v("操作系统导论：主要围绕虚拟化内存，进程并发和持久化（日志文件系统）展开.")]),v._v(" "),_("p",[_("strong",[v._v("1、协程和线程的区别")])]),v._v(" "),_("p",[v._v("线程和协程都是用于实现并发编程的技术，但是它们有一些重要的区别：")]),v._v(" "),_("ol",[_("li",[v._v("调度方式：线程是由操作系统进行调度的，而协程是由程序自己控制的。线程的调度是由操作系统的内核完成的，这需要从用户态切换到内核态，开销较大；而协程的调度则是在用户态完成的，开销较小。")]),v._v(" "),_("li",[v._v("资源占用：线程是操作系统级别的实体，需要分配操作系统资源（如内存）来支持。每个线程需要一定的堆栈空间和上下文切换所需的开销，因此线程的数量受到限制。协程则是在程序中实现的，不需要额外的资源分配，因此可以创建数量更多的协程。")]),v._v(" "),_("li",[v._v("通信方式：线程之间通信通常使用共享内存或消息传递等方式，需要进行同步和互斥操作，以避免竞争条件和死锁。协程则使用更轻量级的方式，通常通过yield、await等语句进行协作式的交互，不需要使用锁和信号量等机制。")]),v._v(" "),_("li",[v._v("粒度：线程是较粗粒度的并发单元，因为每个线程都需要有自己的堆栈和上下文切换的开销。协程则是更细粒度的并发单元，因为它们可以在一个线程内进行切换，不需要切换堆栈和上下文，因此协程的切换开销较小。")])]),v._v(" "),_("p",[v._v("总的来说，协程比线程更加轻量级和灵活，但是需要程序员自己控制调度和协作方式，需要更加谨慎地编写代码，以避免竞争和死锁等问题。")]),v._v(" "),_("p",[_("strong",[v._v("2、内核态和用户态如何交互的？")])]),v._v(" "),_("p",[v._v("内核态和用户态是计算机操作系统中的两种不同的运行级别。内核态是操作系统内核的运行级别，具有最高的权限和访问系统资源的能力，而用户态则是应用程序的运行级别，只能访问有限的资源。")]),v._v(" "),_("p",[v._v("当应用程序需要访问系统资源（如文件、网络、设备等）时，它必须向操作系统发送一个系统调用请求。系统调用是一种机制，允许应用程序从用户态切换到内核态，以便在内核态执行一个特殊的函数或服务，然后将结果返回给应用程序。")]),v._v(" "),_("p",[v._v("当应用程序发送系统调用请求时，操作系统将控制权从用户态切换到内核态，然后执行请求的服务或函数。在执行完成后，操作系统将结果返回给应用程序，并将控制权切换回用户态。这个过程被称为用户态和内核态的上下文切换。")]),v._v(" "),_("p",[v._v("上下文切换的过程包括保存当前运行环境的状态（如寄存器、堆栈等），切换到新的环境，执行请求的服务或函数，然后恢复之前保存的状态。由于上下文切换需要一定的时间和资源，因此需要注意在应用程序中尽可能减少系统调用的数量，以提高性能和效率。")]),v._v(" "),_("p",[_("strong",[v._v("3、常用的Linux命令")])]),v._v(" "),_("p",[v._v("根据进程号查询端口号： netstat -anp |grep 4118")]),v._v(" "),_("p",[v._v("根据端口号查询进程号： lsof -i :8080")]),v._v(" "),_("p",[_("strong",[v._v("一、硬件结构")])]),v._v(" "),_("p",[_("strong",[v._v("1、CPU是如何执行程序的？")])]),v._v(" "),_("p",[v._v("64 位相比 32 位 CPU 的优势主要体现在两个方面：")]),v._v(" "),_("ul",[_("li",[v._v("64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以"),_("strong",[v._v("只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大")]),v._v("。")]),v._v(" "),_("li",[v._v("通常来说 64 位 CPU 的地址总线是 48 位，而 32 位 CPU 的地址总线是 32 位，所以 64 位 CPU 可以"),_("strong",[v._v("寻址更大的物理内存空间")]),v._v("。如果一个 32 位 CPU 的地址总线是 32 位，那么该 CPU 最大寻址能力是 4G，即使你加了 8G 大小的物理内存，也还是只能寻址到 4G 大小的地址，而如果一个 64 位 CPU 的地址总线是 48 位，那么该 CPU 最大寻址能力是 "),_("code",[v._v("2^48")]),v._v("，远超于 32 位 CPU 最大寻址能力。")])]),v._v(" "),_("blockquote",[_("p",[v._v("你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？")])]),v._v(" "),_("p",[v._v("64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的：")]),v._v(" "),_("ul",[_("li",[v._v("如果 32 位指令在 64 位机器上执行，需要一套兼容机制，就可以做到兼容运行了。但是"),_("strong",[v._v("如果 64 位指令在 32 位机器上执行，就比较困难了，因为 32 位的寄存器存不下 64 位的指令")]),v._v("；")]),v._v(" "),_("li",[v._v("操作系统其实也是一种程序，我们也会看到操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位，比如 64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。")])]),v._v(" "),_("p",[v._v("总之，硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽")]),v._v(" "),_("p",[_("strong",[v._v("2、如何写出让CPU跑的更快的代码？")])]),v._v(" "),_("p",[v._v("直接映射、全相连，组相连。由于随着计算机技术的发展，CPU 与 内存的访问速度相差越来越多，如今差距已经高达好几百倍了，所以 CPU 内部嵌入了 CPU Cache 组件，作为内存与 CPU 之间的缓存层，CPU Cache 由于离 CPU 核心很近，所以访问速度也是非常快的，但由于所需材料成本比较高，它不像内存动辄几个 GB 大小，而是仅有几十 KB 到 MB 大小。")]),v._v(" "),_("p",[v._v("当 CPU 访问数据的时候，先是访问 CPU Cache，如果缓存命中的话，则直接返回数据，就不用每次都从内存读取数据了。因此，缓存命中率越高，代码的性能越好。")]),v._v(" "),_("p",[v._v("但需要注意的是，当 CPU 访问数据时，如果 CPU Cache 没有缓存该数据，则会从内存读取数据，但是并不是只读一个数据，而是一次性读取一块一块的数据存放到 CPU Cache 中，之后才会被 CPU 读取。")]),v._v(" "),_("p",[v._v("内存地址映射到 CPU Cache 地址里的策略有很多种，其中比较简单是直接映射 Cache，它巧妙的把内存地址拆分成「索引 + 组标记 + 偏移量」的方式，使得我们可以将很大的内存地址，映射到很小的 CPU Cache 地址里。")]),v._v(" "),_("p",[v._v("要想写出让 CPU 跑得更快的代码，就需要写出缓存命中率高的代码，CPU L1 Cache 分为数据缓存和指令缓存，因而需要分别提高它们的缓存命中率：")]),v._v(" "),_("ul",[_("li",[v._v("对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；")]),v._v(" "),_("li",[v._v("对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；")])]),v._v(" "),_("p",[v._v("另外，对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。")]),v._v(" "),_("p",[v._v("局部性原理和CPU Cache Line得到结构。内存地址结构映射到Cache Line，组标记+索引+偏移量")]),v._v(" "),_("p",[_("strong",[v._v("3、CPU缓存一致性")])]),v._v(" "),_("p",[v._v("CPU 在读写数据的时候，都是在 CPU Cache 读写数据的，原因是 Cache 离 CPU 很近，读写性能相比内存高出很多。对于 Cache 里没有缓存 CPU 所需要读取的数据的这种情况，CPU 则会从内存读取数据，并将数据缓存到 Cache 里面，最后 CPU 再从 Cache 读取数据。")]),v._v(" "),_("p",[v._v("而对于数据的写入，CPU 都会先写入到 Cache 里面，然后再在找个合适的时机写入到内存，那就有「写直达」和「写回」这两种策略来保证 Cache 与内存的数据一致性：")]),v._v(" "),_("ul",[_("li",[v._v("写直达，只要有数据写入，都会直接把数据写入到内存里面，这种方式简单直观，但是性能就会受限于内存的访问速度；")]),v._v(" "),_("li",[v._v("写回，对于已经缓存在 Cache 的数据的写入，只需要更新其数据就可以，不用写入到内存，只有在需要把缓存里面的脏数据交换出去的时候，才把数据同步到内存里，这种方式在缓存命中率高的情况，性能会更好；")])]),v._v(" "),_("p",[v._v("当今 CPU 都是多核的，每个核心都有各自独立的 L1/L2 Cache，只有 L3 Cache 是多个核心之间共享的。所以，我们要确保多核缓存是一致性的，否则会出现错误的结果。")]),v._v(" "),_("p",[v._v("要想实现缓存一致性，关键是要满足 2 点：")]),v._v(" "),_("ul",[_("li",[v._v("第一点是写传播，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；")]),v._v(" "),_("li",[v._v("第二点是事物的串行化，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；")])]),v._v(" "),_("p",[v._v("基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。")]),v._v(" "),_("p",[v._v("MESI 协议，是已修改、独占、共享、已失效这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。")]),v._v(" "),_("p",[_("strong",[v._v("4、CPU是如何执行任务的？")])]),v._v(" "),_("p",[v._v("理解 CPU 是如何读写数据的前提，是要理解 CPU 的架构，CPU 内部的多个 Cache + 外部的内存和磁盘都就构成了金字塔的存储器结构，在这个金字塔中，越往下，存储器的容量就越大，但访问速度就会小。")]),v._v(" "),_("p",[v._v("CPU 读写数据的时候，并不是按一个一个字节为单位来进行读写，而是以 CPU Cache Line 大小为单位，CPU Cache Line 大小一般是 64 个字节，也就意味着 CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作。")]),v._v(" "),_("p",[v._v("因此，如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。")]),v._v(" "),_("p",[v._v("所谓的 Cache Line 伪共享问题就是，多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象。那么对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。")]),v._v(" "),_("p",[v._v("系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。")]),v._v(" "),_("p",[_("strong",[v._v("5、什么是软中断？")])]),v._v(" "),_("p",[v._v("为了避免由于中断处理程序执行时间过长，而影响正常进程的调度，Linux 将中断处理程序分为上半部和下半部：")]),v._v(" "),_("ul",[_("li",[v._v("上半部，对应硬中断，由硬件触发中断，用来快速处理中断；")]),v._v(" "),_("li",[v._v("下半部，对应软中断，由内核触发中断，用来异步处理上半部未完成的工作；")])]),v._v(" "),_("p",[v._v("Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看 /proc/softirqs 来观察软中断的累计中断次数情况，如果要实时查看中断次数的变化率，可以使用 watch -d cat /proc/softirqs 命令。")]),v._v(" "),_("p",[v._v("每一个 CPU 都有各自的软中断内核线程，我们还可以用 ps 命令来查看内核线程，一般名字在中括号里面到，都认为是内核线程。")]),v._v(" "),_("p",[v._v("如果在 top 命令发现，CPU 在软中断上的使用率比较高，而且 CPU 使用率最高的进程也是软中断 ksoftirqd 的时候，这种一般可以认为系统的开销被软中断占据了。")]),v._v(" "),_("p",[v._v("这时我们就可以分析是哪种软中断类型导致的，一般来说都是因为网络接收软中断导致的，如果是的话，可以用 sar 命令查看是哪个网卡的有大量的网络包接收，再用 tcpdump 抓网络包，做进一步分析该网络包的源头是不是非法地址，如果是就需要考虑防火墙增加规则，如果不是，则考虑硬件升级等。")]),v._v(" "),_("p",[_("strong",[v._v("进程和线程的区别？")])]),v._v(" "),_("p",[v._v("PCB是进程唯一的标识，主要包括进程描述符信息：进程标识符，用户标识符")]),v._v(" "),_("p",[v._v("进程控制和管理信息：进程当前的状态信息，进程的优先级")]),v._v(" "),_("p",[v._v("资源分配清单：有关虚拟地址空间的信息，打开文件表和所使用的IO设备信息")]),v._v(" "),_("p",[v._v("CPU相关的信息：CPU中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行 。")]),v._v(" "),_("p",[_("strong",[v._v("JVM进程和操作系统进程的区别？")])]),v._v(" "),_("p",[v._v("JVM进程和操作系统的进程有一些区别，如下所述：")]),v._v(" "),_("ol",[_("li",[v._v("JVM进程是在操作系统的进程之上运行的，它是一个虚拟机进程，而操作系统进程是由操作系统本身管理的。")]),v._v(" "),_("li",[v._v("JVM进程是Java虚拟机进程，它是为了运行Java程序而创建的。操作系统进程则可以运行任何类型的程序。")]),v._v(" "),_("li",[v._v("JVM进程通常运行在一个操作系统进程内，但是一个操作系统进程可以同时运行多个JVM进程。")]),v._v(" "),_("li",[v._v("JVM进程有自己的内存管理和垃圾回收机制，而操作系统进程则由操作系统负责管理和保护。")]),v._v(" "),_("li",[v._v("JVM进程通常具有与Java相关的特定设置和配置，例如类路径和Java虚拟机参数，而操作系统进程则有其自己的特定设置和配置。")])]),v._v(" "),_("p",[v._v("总之，JVM进程是专门为Java程序而创建的，而操作系统进程则是操作系统本身的一部分，可以运行任何类型的程序。JVM进程通常运行在操作系统进程内，但是它们具有自己的内存管理和垃圾回收机制，并具有与Java相关的特定设置和配置。")])])}),[],!1,null,null,null);_.default=U.exports}}]);